---
title: Nvidia Triton
disquis: PythonBiellaGroup
tags:
    - nvidia triton
    - model serving
---

## Intro

In this meeting, we discover NVIDIA Triton, an open-source tool that allows for the deployment of machine learning models.

With a simple configuration of a Docker image, it's possible to create a machine learning inference service capable of doing everything we might desire: serving models from all major Python frameworks, automatic scaling, dynamic batching, online model updates, pipelines, metrics, and more.

## Material

[![Github](https://img.shields.io/badge/GitHub-181717.svg?style=for-the-badge&logo=GitHub&logoColor=white)](https://github.com/PythonBiellaGroup/MaterialeSerate/tree/master/nvidia-triton)

## Meetup video
<iframe width="560" height="315" src="https://www.youtube.com/embed/9WGiH0Tklxk" title="You[label](nvidia_triton.md)Tube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen></iframe>